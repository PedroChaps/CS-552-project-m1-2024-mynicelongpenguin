{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your API key (on the e-mail)\n",
    "# Andre: 4eadeb76-03d6-40cc-b858-27b0da441ac5\n",
    "# Pedro: 175accd9-4b3d-42a7-998e-85600fa3d1f4\n",
    "# Pierre: 7a1ed46e-6371-445e-a383-cc6ccf0525fd\n",
    "API_KEY = \"175accd9-4b3d-42a7-998e-85600fa3d1f4\" \n",
    "\n",
    "# Your sciper number. \n",
    "# Andre: 376762\n",
    "# Pedro: 374339\n",
    "# Pierre: 385070\n",
    "SCIPER = 374339 \n",
    "\n",
    "\n",
    "# To actually rank the preference pairs, or to not save anything (so we can e.g. adjust the prompt we pass to ChatGPT)\n",
    "playground = True\n",
    "\n",
    "import gpt_wrapper\n",
    "gpt_wrapper.api_base = \"http://mnlp-backend-938795011.eu-central-1.elb.amazonaws.com\"\n",
    "gpt_wrapper.api_key = API_KEY\n",
    "\n",
    "from gpt_wrapper.chat import Chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Howdy! :D\n",
      "Missing 100 questions!\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import random\n",
    "\n",
    "# Open json file\n",
    "questions = json.load(open(f\"data/{SCIPER}_base.json\"))\n",
    "progress_questions = json.load(open(f\"data/{SCIPER}.json\"))\n",
    "\n",
    "# Save a backup just in case\n",
    "with open(f\"data/{SCIPER}_bak.json\", \"w\") as f:\n",
    "    json.dump(progress_questions, f)\n",
    "\n",
    "num_questions = len(questions)\n",
    "num_progress = len(progress_questions)\n",
    "\n",
    "print(f\"Howdy! :D\")\n",
    "print(f\"Missing {num_questions - num_progress} questions!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'course_id': 3, 'question_id': 6549, 'question_body': 'A particle of mass $m$ is subjected to a harmonic potential \\r\\n\\\\begin{equation}\\r\\n\\\\hat{V}= \\\\frac{1}{2}m\\\\omega^2 \\\\hat{x^2}\\r\\n\\\\end{equation}\\r\\nand, at time $t=0$ it is in a $|\\\\psi(t=0)\\\\rangle$ state determined by the following conditions:\\r\\n\\\\begin{enumerate}\\r\\n\\\\item each energy measurement gives certain values $E$ which satisfy the relation $ \\\\hbar \\\\omega < E < 3\\\\hbar \\\\omega $\\r\\n\\\\item the mean value of the energy is $ \\\\langle E \\\\rangle = \\\\frac{11}{6} \\\\hbar \\\\omega $\\r\\n\\\\item the mean value of the position is $ \\\\langle x \\\\rangle = -\\\\sqrt{\\\\frac{8\\\\hbar}{9m\\\\omega}} $\\r\\n\\\\end{enumerate}\\r\\nDetermine all the times $t>0$ when the average value of the position is positive and maximum. \\r\\n[Tip: in what follows, it may be useful to express the position operator in terms of the creation and destruction operators $\\\\hat{a}$ and $\\\\hat{a^{\\\\dagger}}$].', 'question_options': None}\n"
     ]
    }
   ],
   "source": [
    "print(questions[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat1 = Chat.create(\"Test Chat\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You asked who won the FIFA championship in 2018.\n"
     ]
    }
   ],
   "source": [
    "print(chat1.ask(\"What did I ask?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the template for the prompt that will be passed to ChatGPT\n",
    "# Leave the <question> tag where the question should be inserted, as it will later be replaced by the actual question\n",
    "# TODO: make two templates for open-ended and multi-choice questions\n",
    "# TODO: read the suggested papers\n",
    "# TODO: play with the templates to find a good one\n",
    "\n",
    "template_open = \"\"\"\n",
    "Let's think step-by-step. Please answer the following question:\n",
    "<question>\n",
    "\"\"\"\n",
    "\n",
    "template_mcq = \"\"\"\n",
    "Let's think step-by-step. Please answer the following question:\n",
    "<question>\n",
    "\"\"\"\n",
    "\n",
    "# Set the specific question you want to ask\n",
    "if playground:\n",
    "    num_progress = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Asked:\n",
      "\n",
      "Let's think step-by-step. Please answer the following question:\n",
      "Suppose we have the binary plaintext $0011$ and we encrypt it with the Vernam cipher and the binary key $0101$. The ciphertext is\\dots\n",
      "A: $0110$.\n",
      "B: $1000$.\n",
      "C: $0111$.\n",
      "D: $0001$.\n",
      "\n",
      "--------------\n",
      "Answer A:\n",
      "To encrypt using the Vernam cipher, we perform a XOR operation between each bit of the plaintext and the corresponding bit of the key.\n",
      "\n",
      "Plaintext: $0011$\n",
      "Key: $0101$\n",
      "\n",
      "Performing XOR operation:\n",
      "$0 \\oplus 0 = 0$\n",
      "$0 \\oplus 1 = 1$\n",
      "$1 \\oplus 0 = 1$\n",
      "$1 \\oplus 1 = 0$\n",
      "\n",
      "So the ciphertext would be $0110$, which corresponds to option A.\n",
      "--------------\n",
      "Answer B:\n",
      "To encrypt using the Vernam cipher, we perform a bitwise XOR operation between the plaintext and the key.\n",
      "\n",
      "Given:\n",
      "Plaintext: $0011$\n",
      "Key: $0101$\n",
      "\n",
      "Performing the XOR operation:\n",
      "$0011 \\oplus 0101 = 0110$\n",
      "\n",
      "Therefore, the ciphertext is $0110$, so the correct answer is A.\n"
     ]
    }
   ],
   "source": [
    "while num_progress < num_questions:\n",
    "\n",
    "    if playground:\n",
    "        chatA = Chat.create(\"Playground chat A \" + str(random.randint(0, 10000000000)))\n",
    "        chatB = Chat.create(\"Playground chat B \" + str(random.randint(0, 10000000000)))\n",
    "    else:\n",
    "        chatA = Chat.create(\"Chat A for question \" + str(num_progress) + \" \" + str(random.randint(0, 10000000000)))\n",
    "        chatB = Chat.create(\"Chat B for question \" + str(num_progress) + \" \" + str(random.randint(0, 10000000000)))\n",
    "    \n",
    "    template = template_open\n",
    "    \n",
    "    questionData = questions[num_progress]\n",
    "    \n",
    "    question = questionData[\"question_body\"]\n",
    "    if questionData[\"question_options\"] != None:\n",
    "        # if it's a multiple choice question, change the template\n",
    "        template = template_mcq\n",
    "        \n",
    "        options = questionData[\"question_options\"]\n",
    "        for i, option in enumerate(options):\n",
    "            question += f\"\\n{chr(ord('A') + i)}: {option}\"\n",
    "    \n",
    "    toAsk = template.replace(\"<question>\", question)\n",
    "    \n",
    "    responseA = chatA.ask(toAsk)\n",
    "    responseB = chatB.ask(toAsk)\n",
    "    A = str(responseA)\n",
    "    B = str(responseB)\n",
    "    \n",
    "    # Depending on the passed template, change this so that it extracts the answer from the response accordingly\n",
    "    # A_start = response_str.find(\"<A_START>\") + len(\"<A_START>\")\n",
    "    # A_end = response_str.find(\"<A_END>\")\n",
    "    # B_start = response_str.find(\"<B_START>\") + len(\"<B_START>\")\n",
    "    # B_end = response_str.find(\"<B_END>\")\n",
    "    \n",
    "    # A = response_str[A_start:A_end].split(\"A: \")[1].strip()\n",
    "    # B = response_str[B_start:B_end].split(\"B: \")[1].strip()\n",
    "\n",
    "    print(\"Asked:\")\n",
    "    print(toAsk)\n",
    "    print(\"--------------\")\n",
    "    print(\"Answer A:\")\n",
    "    print(A)\n",
    "    print(\"--------------\")\n",
    "    print(\"Answer B:\")\n",
    "    print(B)\n",
    "    \n",
    "    overall, correctness, relevance, clarity, completeness, other = -1, -1, -1, -1, -1, -1\n",
    "    while overall not in [\"A\", \"B\", \"AB\", \"N\"]:\n",
    "        overall = input(\"Overall ranking (A, B, AB, N for None): \")\n",
    "    while correctness not in [\"A\", \"B\", \"AB\", \"N\"]:\n",
    "        correctness = input(\"Correctness ranking (A, B, AB, N): \")\n",
    "    while relevance not in [\"A\", \"B\", \"AB\", \"N\"]:\n",
    "        relevance = input(\"Relevance ranking (A, B, AB, N): \")\n",
    "    while clarity not in [\"A\", \"B\", \"AB\", \"N\"]:\n",
    "        clarity = input(\"Clarity ranking (A, B, AB, N): \")\n",
    "    while completeness not in [\"A\", \"B\", \"AB\", \"N\"]:\n",
    "        completeness = input(\"Completeness ranking (A, B, AB, N): \")\n",
    "    \n",
    "    other = input(\"Other ranking (None or `<criteria1>: <A, B, AB>;<criteria2>: <A, B, AB>;...`): \")\n",
    "    \n",
    "    if overall == \"N\":\n",
    "        overall = \"None\"\n",
    "    if correctness == \"N\":\n",
    "        correctness = \"None\"\n",
    "    if relevance == \"N\":\n",
    "        relevance = \"None\"\n",
    "    if clarity == \"N\":\n",
    "        clarity = \"None\"\n",
    "    if completeness == \"N\":\n",
    "        completeness = \"None\"\n",
    "    if other == \"N\" or other == \"\":\n",
    "        other = \"None\"\n",
    "    \n",
    "    \n",
    "    progress_questions += [{\n",
    "        \"course_id\": questionData[\"course_id\"],\n",
    "        \"question_id\": questionData[\"question_id\"],\n",
    "        \"question\": questionData[\"question_body\"],\n",
    "        \n",
    "        \"A_chat_id\": responseA.chat_id,\n",
    "        \"B_chat_id\": responseB.chat_id,\n",
    "        \n",
    "        \"A\": A, \n",
    "        \"B\": B,\n",
    "        \n",
    "        \"ranking_criteria\": {\n",
    "            \"overall\": overall,  \n",
    "            \"correctness\": correctness,  \n",
    "            \"relevance\": relevance,  \n",
    "            \"clarity\": clarity,  \n",
    "            \"completeness\": completeness,  \n",
    "            \"other\": other,  \n",
    "        }\n",
    "    }] \n",
    "    \n",
    "    # Saves first to a backup file, then to the actual file\n",
    "    if not playground:\n",
    "        with open(f\"data/{SCIPER}_bak.json\", \"w\") as f:\n",
    "            json.dump(progress_questions, f)\n",
    "            \n",
    "        with open(f\"data/{SCIPER}.json\", \"w\") as f:\n",
    "            json.dump(progress_questions, f)\n",
    "\n",
    "        num_progress += 1\n",
    "        \n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
