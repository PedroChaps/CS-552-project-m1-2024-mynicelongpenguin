{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your API key (on the e-mail)\n",
    "# Andre: 4eadeb76-03d6-40cc-b858-27b0da441ac5\n",
    "# Pedro: 175accd9-4b3d-42a7-998e-85600fa3d1f4\n",
    "# Pierre: 7a1ed46e-6371-445e-a383-cc6ccf0525fd\n",
    "API_KEY = \"4eadeb76-03d6-40cc-b858-27b0da441ac5\" \n",
    "\n",
    "# Your sciper number. \n",
    "# Andre: 376762\n",
    "# Pedro: 374339\n",
    "# Pierre: 385070\n",
    "SCIPER = 376762\n",
    "\n",
    "\n",
    "# To actually rank the preference pairs, or to not save anything (so we can e.g. adjust the prompt we pass to ChatGPT)\n",
    "playground = False\n",
    "\n",
    "import gpt_wrapper\n",
    "gpt_wrapper.api_base = \"http://mnlp-backend-938795011.eu-central-1.elb.amazonaws.com\"\n",
    "gpt_wrapper.api_key = API_KEY\n",
    "\n",
    "from gpt_wrapper.chat import Chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Howdy! :D\n",
      "Missing 0 questions!\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import random\n",
    "\n",
    "# Open json file\n",
    "questions = json.load(open(f\"data/{SCIPER}_base.json\"))\n",
    "progress_questions = json.load(open(f\"data/{SCIPER}.json\"))\n",
    "\n",
    "# Save a backup just in case\n",
    "with open(f\"data/{SCIPER}_bak.json\", \"w\") as f:\n",
    "    json.dump(progress_questions, f)\n",
    "\n",
    "num_questions = len(questions)\n",
    "num_progress = len(progress_questions)\n",
    "\n",
    "print(f\"Howdy! :D\")\n",
    "print(f\"Missing {num_questions - num_progress} questions!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'course_id': 0, 'question_id': 5738, 'question_body': 'The Murphy Law states that if there is a single security hole in an exposed cryptosystem, then\\\\dots', 'question_options': ['hope for the best', 'nobody will look for it', 'nobody will find it', 'someone will ultimately find it']}\n"
     ]
    }
   ],
   "source": [
    "print(questions[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat1 = Chat.create(\"Test Chat\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You asked, \"What did I ask?\"\n"
     ]
    }
   ],
   "source": [
    "print(chat1.ask(\"What did I ask?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the template for the prompt that will be passed to ChatGPT\n",
    "# Leave the <question> tag where the question should be inserted, as it will later be replaced by the actual question\n",
    "# TODO: make two templates for open-ended and multi-choice questions\n",
    "# TODO: read the suggested papers\n",
    "# TODO: play with the templates to find a good one\n",
    "template_open_A = \"\"\"\n",
    "From now on, act as a student at École Polytechnique Fédérale de Lausanne (EPFL) doing a test. You are about to answer a question. Pay close attention to the theme of the question (Physics, thermodynamics, ...) and think step-by-step when answering the question. \n",
    "Please explain the reasoning and assumptions behind your answer. If possible, use specific examples or evidence to support your answer of why it is correct. Moreover, only and only when strictly related to the question and not obvious, address any potential ambiguities or limitations in your answer, in order to provide a more complete and accurate response.<latex>\n",
    "\n",
    "\n",
    "The question is:\n",
    "<question>\n",
    "\"\"\"\n",
    "\n",
    "template_mcq_A = \"\"\"\n",
    "From now on, act as a student at École Polytechnique Fédérale de Lausanne (EPFL) doing a test. You are about to answer a question. Pay close attention to the theme of the question (Physics, thermodynamics, ...) and think step-by-step when answering the question.<latex>\n",
    "\n",
    "\n",
    "The question is:\n",
    "<question>\n",
    "\"\"\"\n",
    "\n",
    "template_open_B = \"\"\"\n",
    "Q: <question>\n",
    "\n",
    "\n",
    "\n",
    "A: Let's think step-by-step. \n",
    "\"\"\"\n",
    "\n",
    "template_mcq_B = \"\"\"\n",
    "Question:\n",
    "\n",
    "<question>\n",
    "\n",
    "\n",
    "\n",
    "Answer: Let's think step-by-step. \n",
    "\"\"\"\n",
    "\n",
    "# template_open = \"\"\"\n",
    "#     From now on, act as a student at École polytechnique fédérale de Lausanne (EPFL)  doing a test. You are about to answer a question. Pay close attention to the theme of the question (Physics, thermodynamics, ...) and think step-by-step when answering the question. \n",
    "# Please explain the reasoning and assumptions behind your answer. If possible, use specific examples or evidence to support your answer of why it is correct. Moreover, please address any potential ambiguities or limitations in your answer,  only if the limitations are not obvious and strictly related to the question, in order to provide a more complete and accurate response.\n",
    "\n",
    "# The question is:\n",
    "# <question>\n",
    "# \"\"\"\n",
    "# template_open = \"\"\"\n",
    "# Let's think step-by-step. Please answer the following question:\n",
    "# <question>\n",
    "# \"\"\"\n",
    "\n",
    "# template_mcq = \"\"\"\n",
    "# Let's think step-by-step. Please answer the following question:\n",
    "# <question>\n",
    "# \"\"\"\n",
    "\n",
    "# Set the specific question you want to ask\n",
    "if playground:\n",
    "    num_progress = 93"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import latex_commands\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "while num_progress < num_questions:\n",
    "\n",
    "    if playground:\n",
    "        chatA = Chat.create(\"Playground chat A \" + str(random.randint(0, 10000000000)))\n",
    "        chatB = Chat.create(\"Playground chat B \" + str(random.randint(0, 10000000000)))\n",
    "    else:\n",
    "        chatA = Chat.create(\"Chat A for question \" + str(num_progress) + \" \" + str(random.randint(0, 10000000000)))\n",
    "        chatB = Chat.create(\"Chat B for question \" + str(num_progress) + \" \" + str(random.randint(0, 10000000000)))\n",
    "    \n",
    "    template_A = template_open_A\n",
    "    template_B = template_open_B\n",
    "    \n",
    "    questionData = questions[num_progress]\n",
    "    \n",
    "    question = questionData[\"question_body\"]\n",
    "    \n",
    "    if questionData[\"question_options\"] != None:\n",
    "        # if it's a multiple choice question, change the template\n",
    "        template_A = template_mcq_A\n",
    "        template_B = template_mcq_B\n",
    "        \n",
    "        options = questionData[\"question_options\"]\n",
    "        for i, option in enumerate(options):\n",
    "            question += f\"\\n{chr(ord('A') + i)}: {option}\"\n",
    "    \n",
    "    toAsk_A = template_A.replace(\"<question>\", question)\n",
    "    toAsk_B = template_B.replace(\"<question>\", question)\n",
    "    if any([command in question for command in latex_commands.commands]):\n",
    "        toAsk_A = toAsk_A.replace(\"<latex>\", \" The question contains LaTeX commands. Please take this into account when answering.\") \n",
    "    else:\n",
    "        toAsk_A = toAsk_A.replace(\"<latex>\", \"\")\n",
    "\n",
    "    print(\"Asked A:\")\n",
    "    print(toAsk_A)\n",
    "    print(\"--------------\")\n",
    "    print(\"Asked B:\")\n",
    "    print(toAsk_B)\n",
    "   \n",
    "    # model_args = {\n",
    "    #     \"temperature\": 0.5,\n",
    "    #     \"top_p\": 0.95\n",
    "    # }\n",
    "    \n",
    "    responseA = chatA.ask(toAsk_A)\n",
    "    # responseA = \"\"\n",
    "    responseB = chatB.ask(toAsk_B)\n",
    "    A = str(responseA)\n",
    "    B = str(responseB)\n",
    "    \n",
    "    # Depending on the passed template, change this so that it extracts the answer from the response accordingly\n",
    "    # A_start = response_str.find(\"<A_START>\") + len(\"<A_START>\")\n",
    "    # A_end = response_str.find(\"<A_END>\")\n",
    "    # B_start = response_str.find(\"<B_START>\") + len(\"<B_START>\")\n",
    "    # B_end = response_str.find(\"<B_END>\")\n",
    "    \n",
    "    # A = response_str[A_start:A_end].split(\"A: \")[1].strip()\n",
    "    # B = response_str[B_start:B_end].split(\"B: \")[1].strip()\n",
    "\n",
    "    \n",
    "    print(\"--------------\")\n",
    "    print(\"Answer A:\")\n",
    "    print(A)\n",
    "    print(\"--------------\")\n",
    "    print(\"Answer B:\")\n",
    "    print(B)\n",
    "    repeat = -1\n",
    "    while repeat != \"n\" :\n",
    "        repeat = input(\"Repeat? (y/n): \") \n",
    "        if repeat == \"y\":\n",
    "            if playground:\n",
    "                chatA = Chat.create(\"Playground chat A \" + str(random.randint(0, 10000000000)))\n",
    "                chatB = Chat.create(\"Playground chat B \" + str(random.randint(0, 10000000000)))\n",
    "            else:\n",
    "                chatA = Chat.create(\"Chat A for question \" + str(num_progress) + \" \" + str(random.randint(0, 10000000000)))\n",
    "                chatB = Chat.create(\"Chat B for question \" + str(num_progress) + \" \" + str(random.randint(0, 10000000000)))\n",
    "            \n",
    "            responseA = chatA.ask(toAsk_A)\n",
    "            responseB = chatB.ask(toAsk_B)\n",
    "            A = str(responseA)\n",
    "            B = str(responseB)\n",
    "            print(\"---AFTER REP-----------\")\n",
    "            print(\"Answer A:\")\n",
    "            print(A)\n",
    "            print(\"--------------\")\n",
    "            print(\"Answer B:\")\n",
    "            print(B)\n",
    "        \n",
    "    overall, correctness, relevance, clarity, completeness, other = -1, -1, -1, -1, -1, -1\n",
    "    while overall not in [\"A\", \"B\", \"AB\", \"N\"]:\n",
    "        overall = input(\"Overall ranking (A, B, AB, N for None): \")\n",
    "    while correctness not in [\"A\", \"B\", \"AB\", \"N\"]:\n",
    "        correctness = input(\"Correctness ranking (A, B, AB, N): \")\n",
    "    while relevance not in [\"A\", \"B\", \"AB\", \"N\"]:\n",
    "        relevance = input(\"Relevance ranking (A, B, AB, N): \")\n",
    "    while clarity not in [\"A\", \"B\", \"AB\", \"N\"]:\n",
    "        clarity = input(\"Clarity ranking (A, B, AB, N): \")\n",
    "    while completeness not in [\"A\", \"B\", \"AB\", \"N\"]:\n",
    "        completeness = input(\"Completeness ranking (A, B, AB, N): \")\n",
    "    \n",
    "    other = input(\"Other ranking (None or `<criteria1>: <A, B, AB>;<criteria2>: <A, B, AB>;...`): \")\n",
    "    \n",
    "    if overall == \"N\":\n",
    "        overall = \"None\"\n",
    "    if correctness == \"N\":\n",
    "        correctness = \"None\"\n",
    "    if relevance == \"N\":\n",
    "        relevance = \"None\"\n",
    "    if clarity == \"N\":\n",
    "        clarity = \"None\"\n",
    "    if completeness == \"N\":\n",
    "        completeness = \"None\"\n",
    "    if other == \"N\" or other == \"\":\n",
    "        other = \"None\"\n",
    "    \n",
    "    \n",
    "    progress_questions += [{\n",
    "        \"course_id\": questionData[\"course_id\"],\n",
    "        \"question_id\": questionData[\"question_id\"],\n",
    "        \"question\": questionData[\"question_body\"],\n",
    "        \n",
    "        \"A_chat_id\": responseA.chat_id,\n",
    "        \"B_chat_id\": responseB.chat_id,\n",
    "        \n",
    "        \"A\": A, \n",
    "        \"B\": B,\n",
    "        \n",
    "        \"ranking_criteria\": {\n",
    "            \"overall\": overall,  \n",
    "            \"correctness\": correctness,  \n",
    "            \"relevance\": relevance,  \n",
    "            \"clarity\": clarity,  \n",
    "            \"completeness\": completeness,  \n",
    "            \"other\": other,  \n",
    "        }\n",
    "    }] \n",
    "    \n",
    "    # Saves first to a backup file, then to the actual file\n",
    "    if not playground:\n",
    "        with open(f\"data/{SCIPER}_bak.json\", \"w\") as f:\n",
    "            json.dump(progress_questions, f)\n",
    "            \n",
    "        with open(f\"data/{SCIPER}.json\", \"w\") as f:\n",
    "            json.dump(progress_questions, f)\n",
    "\n",
    "        num_progress += 1\n",
    "        \n",
    "    clear_output(False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
